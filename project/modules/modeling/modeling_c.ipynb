{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee9eb6-4b9c-4b5d-81f4-3d03848c58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "# import Random Forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Check accuracy score \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "# training the model on training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, LabelEncoder, MinMaxScaler, MaxAbsScaler, RobustScaler, Normalizer, QuantileTransformer, PowerTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d1689-6298-46f3-a334-9c28852ba516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to dataframe\n",
    "df_missing = pd.read_csv('../../../data/clean_data/data_clean_missing.csv')\n",
    "\n",
    "\n",
    "# constrain duration_ms to <= 700,000 ms due to outliers\n",
    "df_constrain = df_missing[df_missing['duration_ms'] <= 700000]\n",
    "\n",
    "#replace missing values with nan\n",
    "df_constrain = df_constrain.replace([-1, '?'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bfa5f8-4c19-4e47-97f9-0f5379e65e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute duration and tempo columns using the mean strategy\n",
    "#imp_mean = SimpleImputer(strategy='mean')\n",
    "#imp_mean = SimpleImputer(strategy='median')\n",
    "#imp_mean = KNNImputer()\n",
    "imp_mean = IterativeImputer(random_state=0, initial_strategy='median')\n",
    "df_constrain['duration_ms_imp'] = imp_mean.fit_transform(df_constrain[['duration_ms']])\n",
    "\n",
    "imp_median = IterativeImputer(random_state=0, initial_strategy='median')\n",
    "#imp_median = KNNImputer()\n",
    "#imp_median = SimpleImputer(strategy='median')\n",
    "df_constrain['tempo_imp'] = imp_median.fit_transform(df_constrain[['tempo']])\n",
    "\n",
    "# drop original columns\n",
    "df_constrain.drop(['duration_ms', 'tempo'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e66321-3fce-45fd-8fea-4f1bb70b779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace Rap with Hip-Hop\n",
    "df_constrain['music_genre'].replace({'Rap': 'Hip-Hop'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b045db-13a8-42bd-a70a-2715d1cd9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_constrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8c68b-3544-4f43-a912-3e46544abff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize each feature for encoding or scaling\n",
    "cat_feats = ['artist_name', 'key', 'mode', 'music_genre']\n",
    "cat_feats_ohe = ['artist_name', 'mode']\n",
    "cat_feats_le = ['music_genre']\n",
    "\n",
    "num_feats = ['popularity', 'acousticness','danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "num_feats_scale = ['popularity', 'duration_ms_imp', 'loudness', 'tempo_imp']\n",
    "num_feats_imp_mean = ['duration_ms']\n",
    "num_feats_imp_median = ['tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a86a2f-d479-42e6-bc4a-22870748cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features\n",
    "feats = ['popularity', 'acousticness','danceability', 'duration_ms_imp', 'energy', 'instrumentalness', 'loudness', 'speechiness', 'tempo_imp', 'valence', 'mode_Major', 'mode_Minor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3fcff8-9f37-455a-8cbe-28ab15cc3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate labelencoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# apply le on categorical feature columns\n",
    "df_subset[cat_feats_le] = df_subset[cat_feats_le].apply(lambda col: le.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1bfcd3-8766-4149-b088-5d5c2cca80a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummy variables for categorical variables\n",
    "df_out = pd.get_dummies(df_subset, columns = cat_feats_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f96fb-9aa7-4312-b8f6-301b8692539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of unwanted values for artist names\n",
    "df_out.columns = df_out.columns.str.translate(\"\".maketrans({\"[\":\"{\", \"]\":\"}\",\"<\":\"^\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c66522-0349-44c4-a0ba-4365b436f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make custom map for key column\n",
    "dic = {'C': 0, 'C#': 1, 'D': 2, 'D#': 3, 'E': 4,\n",
    "       'F': 5, 'F#': 6, 'G': 7, 'G#': 8, 'A': 9,\n",
    "       'A#': 10, 'B': 11}\n",
    "\n",
    "# use custom map on key column\n",
    "df_out.replace({\"key\": dic}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee49f329-016f-466f-88fa-893460ede9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features that need to be scaled\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_out[num_feats_scale] = scaler.fit_transform(df_subset[num_feats_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab0bb9-5234-46e7-afe4-8f8fe5487a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify target variable\n",
    "df_target = df_out['music_genre']\n",
    "\n",
    "# identify input variables\n",
    "df_input = df_out.drop(['music_genre'], axis=1)\n",
    "#'key', 'mode_Major', 'mode_Minor', 'liveness'\n",
    "\n",
    "\n",
    "# make separate input for feature selection\n",
    "# df_input_selection = df_subset.drop(['music_genre', 'liveness', 'key', 'energy', 'valence', 'duration_ms_imp', 'tempo_imp'], axis=1)\n",
    "\n",
    "# make separate input for feature selection\n",
    "# df_input_selection = df_subset[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d122ef12-186a-474f-aff5-fc56f107be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cffd0a-117c-42ed-ab1c-438b08aba582",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_input, df_target, test_size=0.3, random_state=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d0cf85-f669-4bbb-a767-7b2f91a843db",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = xgb.XGBClassifier(objective= 'multi:softmax', colsample_bytree = 0.3, learning_rate = 0.2,\n",
    "                max_depth = 5, alpha = 0.5, n_estimators = 100, num_class = 9, use_label_encoder=False)\n",
    "\n",
    "xg_clf.fit(X_train,y_train)\n",
    "\n",
    "pred_clf = xg_clf.predict(X_test)\n",
    "\n",
    "print(xg_clf.feature_importances_)\n",
    "\n",
    "# Check accuracy score\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, pred_clf)))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, pred_clf, average = None))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, pred_clf, average = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d4c459-fb44-4c95-addd-42a939c16d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xg_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cdaaba-6860-4d20-8832-cdd4cce497e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_opt = {'objective': 'multi:softmax', 'use_label_encoder': False, 'colsample_bytree': 0.6258986644606082, 'gamma': 1.4497823418113986, 'learning_rate': 0.47434885295765056,\n",
    "              'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 0.733163084214365}\n",
    "\n",
    "# params_opt = {'objective': 'multi:softmax', 'use_label_encoder': False, 'colsample_bytree': 0.7715942963067712, 'gamma': 0.10686394019950783, 'learning_rate': 0.09710945761615764,\n",
    "#               'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 300, 'reg_alpha': 0.3027723368940669, 'reg_lambda': 1.5894437328567554}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d59d3-c1f5-4285-9891-c0188a1fa434",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf_opt = xgb.XGBClassifier(**params_opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1239f47f-2cf8-4066-b0c8-90829559f3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf_opt.fit(X_train,y_train)\n",
    "pred_clf_opt = xg_clf_opt.predict(X_test)\n",
    "\n",
    "print(xg_clf_opt.feature_importances_)\n",
    "\n",
    "# Check accuracy score\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, pred_clf_opt)))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, pred_clf_opt, average = None))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, pred_clf_opt, average = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c11f0d-327c-4a90-a257-e2f3b080a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_clf_opt, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069fc06-a62a-4baa-88e1-d3293f871137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'xgb_opt_model2.sav'\n",
    "pickle.dump(xg_clf_opt, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde90aa3-731f-4c72-a00f-0cf34ca328b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open('xgb_opt_model2.sav', 'rb'))\n",
    "result = loaded_model.predict(X_test)\n",
    "\n",
    "# Check accuracy score\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429183a7-da5e-45e4-9b7e-ed71ea153f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open('xgboost_baseline_model.sav', 'rb'))\n",
    "result = loaded_model.predict(X_test)\n",
    "\n",
    "# Check accuracy score\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbaaf9e-8076-4d6b-ae99-a746d32bca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(loaded_model, max_num_features = 14)\n",
    "# plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c11dc1-893f-4264-afb9-6678c941b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xg_clf_opt, max_num_features = 8)\n",
    "# plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c7d6d-243f-4120-b95c-40187087142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_clf, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d297e12-9daa-4b62-970c-be84c817682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923bd78c-cee8-49ba-900d-38e43ab8f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalized=True, cmap='bone'):\n",
    "    plt.figure(figsize=[7, 6])\n",
    "    norm_cm = cm\n",
    "    if normalized:\n",
    "        norm_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        sns.heatmap(norm_cm, annot=cm, fmt='g', xticklabels=classes, yticklabels=classes, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c071330-91d0-4bf1-9bfa-bc5861022bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cm = confusion_matrix(y_test, preds)\n",
    "plot_confusion_matrix(xgb_cm, classes=le.classes_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dcdad0-0171-4e09-8274-bc91aea8f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import cv\n",
    "\n",
    "params = {'objective':'multi:softmax', 'colsample_bytree': 0.3, 'learning_rate': 0.2,\n",
    "                'max_depth': 5, 'alpha': 0.5, 'n_estimators': 100, 'num_class': 9, 'use_label_encoder': False}\n",
    "\n",
    "xgb_cv = cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50, early_stopping_rounds=10, metrics=\"auc\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e87dbb-5bfd-4fc1-9a24-faf8debbab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43d4a0-6bef-4138-b46f-bc80645b3a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, Trials, fmin, tpe, STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96105b1a-88e3-418c-bac0-9fba20162a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 10, 1),\n",
    "        'gamma': hp.uniform ('gamma', 0,3),\n",
    "        'reg_alpha' : hp.uniform('reg_alpha', 0,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,2),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 5, 1),\n",
    "        'n_estimators': hp.quniform('n_estimators', 50, 350, 100),\n",
    "        'seed': 0,\n",
    "       'learning_rate': hp.uniform('learning_rate', 0.01,1)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81422c-7937-42d5-97f2-254481f34378",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'colsample_bytree': 0.6258986644606082, 'gamma': 1.4497823418113986, 'learning_rate': 0.47434885295765056, 'max_depth': 7.0, 'min_child_weight': 0.0,\n",
    " 'n_estimators': 200.0, 'reg_alpha': 0.1, 'reg_lambda': 0.733163084214365}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ea7161-f3c6-4067-a0fd-a954c4f98410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    clf=xgb.XGBClassifier(\n",
    "                    n_estimators = int(space['n_estimators']), max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = space['reg_alpha'] , min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree= int(space['colsample_bytree']), learning_rate= space['learning_rate'],\n",
    "                    use_label_encoder=False)\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"auc\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b0bc0-478b-4a55-b96e-0868b98153ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699aeb52-d242-42df-8917-1a47c196d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be669332-e27f-465a-8809-1848a044cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68862a4a-92d5-4370-b94a-d60b86b7c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['popularity', 'duration_ms', 'loudness', 'tempo']\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "# define which transformer applies to which columns\n",
    "preprocess = ColumnTransformer([('numeric_transformer', numeric_transformer, numeric_features)\n",
    "])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocess\", preprocess), ('f_classif', SelectKBest(k='all')), (\"xgb\", xg_clf_opt)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37639c5b-0de8-4c63-bcec-a01ec78e2a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_to_test = np.arange(1, 6652)\n",
    "\n",
    "scalers_to_test = [StandardScaler(), RobustScaler(), QuantileTransformer(), MinMaxScaler(), MaxAbsScaler(), Normalizer(), PowerTransformer()]\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"preprocess__numeric_transformer__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    'preprocess__numeric_transformer__scaler': scalers_to_test,\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=10)\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd43ffc-a2d7-437e-8384-3f8979aeb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[0:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3944027-6585-42ab-9fa7-d042413e766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572c5892-748a-4178-871e-57a62994ca73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bootcamp",
   "language": "python",
   "name": "bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
