{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64dff1-6b33-41fe-b4a6-59c673d09fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, LabelEncoder, MinMaxScaler, MaxAbsScaler, RobustScaler, Normalizer, QuantileTransformer, PowerTransformer\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf5b3bf-99f2-4200-bdcb-084082a57b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to dataframe\n",
    "df_missing = pd.read_csv('../../../data/clean_data/data_clean_missing.csv')\n",
    "\n",
    "\n",
    "# constrain duration_ms to <= 700,000 ms due to outliers\n",
    "df_constrain = df_missing[df_missing['duration_ms'] <= 700000]\n",
    "\n",
    "#replace missing values with nan\n",
    "df_constrain = df_constrain.replace([-1, '?'], np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1670227-9418-4a12-892d-333d58cf1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute duration and tempo columns using the mean strategy\n",
    "imp_mean = SimpleImputer(strategy='mean')\n",
    "df_constrain['duration_ms_imp'] = imp_mean.fit_transform(df_constrain[['duration_ms']])\n",
    "\n",
    "imp_median = SimpleImputer(strategy='median')\n",
    "df_constrain['tempo_imp'] = imp_median.fit_transform(df_constrain[['tempo']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c278d726-5434-4bfa-a144-e4775ad112f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original columns\n",
    "df_constrain.drop(['duration_ms', 'tempo'], axis = 1, inplace = True)\n",
    "\n",
    "# replace Rap with Hip-Hop\n",
    "df_constrain['music_genre'].replace({'Rap': 'Hip-Hop'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e9f68-178c-4023-89a4-f6f626ac7c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_constrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bc8537-962b-4076-8f5a-73717323dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick random rows of Hip-Hop music genre to re-balance dataset\n",
    "np.random.seed(10)\n",
    "\n",
    "remove_n = 5000\n",
    "drop_indices = np.random.choice(df_test[df_test['music_genre'] == 'Hip-Hop'].index, remove_n, replace=False)\n",
    "df_subset = df_test.drop(drop_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf32d13-eea5-49b8-b5ce-c6f6241040be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize each feature for encoding or scaling\n",
    "cat_feats = ['artist_name', 'key', 'mode', 'music_genre']\n",
    "cat_feats_ohe = ['artist_name', 'mode']\n",
    "cat_feats_le = ['music_genre']\n",
    "\n",
    "num_feats = ['popularity', 'acousticness','danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "num_feats_scale = ['popularity', 'duration_ms_imp', 'loudness', 'tempo_imp']\n",
    "num_feats_imp_mean = ['duration_ms']\n",
    "num_feats_imp_median = ['tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd5c7e-de55-4226-940d-fba318fda5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features\n",
    "feats = ['popularity', 'acousticness','danceability', 'duration_ms_imp', 'energy', 'instrumentalness', 'loudness', 'speechiness', 'tempo_imp', 'valence', 'mode_Major', 'mode_Minor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ea520-154f-41bc-a3f0-b8c0d51346c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate labelencoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# apply le on categorical feature columns\n",
    "df_subset[cat_feats_le] = df_subset[cat_feats_le].apply(lambda col: le.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026f805-d860-4d9d-8ede-6543cae382d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of unwanted values for artist names\n",
    "df_subset.columns = df_subset.columns.str.translate(\"\".maketrans({\"[\":\"{\", \"]\":\"}\",\"<\":\"^\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3853e226-6a5e-48e1-9a3d-e0bd053580bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummy variables for categorical variables\n",
    "df_out = pd.get_dummies(df_subset, columns = cat_feats_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f738594-af85-40f9-b695-2396ebf0180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make custom map for key column\n",
    "dic = {'C': '0', 'C#': '1', 'D': '2', 'D#': '3', 'E': '4',\n",
    "       'F': '5', 'F#': '6', 'G': '7', 'G#': '8', 'A': '9',\n",
    "       'A#': '10', 'B': '11'}\n",
    "\n",
    "# use custom map on key column\n",
    "df_out.replace({\"key\": dic}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff4312e-99b1-4793-879c-b889905df219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features that need to be scaled\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_out[num_feats_scale] = scaler.fit_transform(df_subset[num_feats_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9796e8-35d3-48a0-ac78-2eb17595981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify target variable\n",
    "df_target = df_scaled['music_genre']\n",
    "\n",
    "# identify input variables\n",
    "df_input = df_scaled.drop('music_genre', axis=1)\n",
    "\n",
    "# make separate input for feature selection\n",
    "df_input_selection = df_scaled.drop(['music_genre', 'liveness', 'key', 'energy', 'valence', 'duration_ms_imp', 'tempo_imp'], axis=1)\n",
    "\n",
    "# make separate input for feature selection\n",
    "df_input_selection = df_scaled[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284eb15-8a03-4ad9-9eb9-1fe9d3129c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_input, df_target, test_size=0.3, random_state=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce63db09-8652-42e5-93fa-b4c56f427425",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_select, X_test_select, y_train_select, y_test_select = train_test_split(df_input_selection, df_target, test_size=0.3, random_state=1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef8b706-c181-41c0-965a-23f602fbbcf2",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae6d5c-8c5c-40fd-a244-40c53c569f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=df_input, label=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cefd0-1160-4e17-8095-3cfc3a24ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective= 'multi:softmax', colsample_bytree = 0.3, learning_rate = 0.2,\n",
    "                max_depth = 5, alpha = 0.5, n_estimators = 100, num_class = 10)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "print(xg_reg.feature_importances_)\n",
    "\n",
    "# Check accuracy score\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, preds)))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, preds, average = None))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, preds, average = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae8f51-be95-4dc2-b38e-c20a92b23474",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xg_reg_select, max_num_features = 10)\n",
    "plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911825cb-2234-4fe6-a05a-bf78237a6420",
   "metadata": {},
   "source": [
    "# Pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a4e9d-aee1-4249-871c-5a8e96fe500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['ApplicantIncome', 'CoapplicantIncome', 'total_income', 'LoanAmount', 'Loan_Amount_Term']\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "\n",
    "categorical_features = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# This dataset is way too high-dimensional. Better do PCA:\n",
    "pca = PCA()\n",
    "\n",
    "# Maybe some of the original features were good, too?\n",
    "selection = SelectKBest()\n",
    "\n",
    "# Build an transformer from PCA and Univariate selection:\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "\n",
    "# We will initialize the classifier\n",
    "svm = SVC(kernel=\"linear\")\n",
    "\n",
    "# create our pipeline from FeatureUnion \n",
    "pipeline = Pipeline([(\"features\", combined_features), (\"svm\", svm)])\n",
    "\n",
    "# set up our parameters grid\n",
    "param_grid = {\"features__pca__n_components\": [1, 2, 3],\n",
    "                  \"features__univ_select__k\": [1, 2, 3],\n",
    "                  \"svm__C\":[0.1, 1, 10]}\n",
    "\n",
    "# create a Grid Search object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, verbose=10, refit=True)    \n",
    "\n",
    "# fit the model and tune parameters\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), ('f_classif', SelectKBest(k=3)), (\"classifier\", RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_clean2, y, test_size=0.2, random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf42e67-c8c0-4f35-be02-6afef6065d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset is way too high-dimensional. Better do PCA:\n",
    "pca = PCA()\n",
    "\n",
    "# Maybe some of the original features were good, too?\n",
    "selection = SelectKBest()\n",
    "\n",
    "# Build an transformer from PCA and Univariate selection:\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "\n",
    "# We will initialize the classifier\n",
    "svm = SVC(kernel=\"linear\")\n",
    "\n",
    "# create our pipeline from FeatureUnion \n",
    "pipeline = Pipeline([(\"features\", combined_features), (\"svm\", svm)])\n",
    "\n",
    "# set up our parameters grid\n",
    "param_grid = {\"features__pca__n_components\": [1, 2, 3],\n",
    "                  \"features__univ_select__k\": [1, 2, 3],\n",
    "                  \"svm__C\":[0.1, 1, 10]}\n",
    "\n",
    "# create a Grid Search object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, verbose=10, refit=True)    \n",
    "\n",
    "# fit the model and tune parameters\n",
    "grid_search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea73e40-6713-4047-95dd-fa0e40106b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    'f_classif__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    \"classifier__n_estimators\": [1, 10, 100],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=10)\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa7ab1-0172-41bf-9637-c1ce45ce5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684743ea-c1ec-47ad-b314-3aa22e42eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(grid_search, open(\"model.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1256e099-2964-4236-950a-ecc9c6ac4f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Internal CV score: {grid_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a3ac18-d3a2-485c-8eb1-a24f1518efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    (\n",
    "        \"best random forest classifier from grid search: %.3f\"\n",
    "        % grid_search.score(X_test, y_test)\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bootcamp",
   "language": "python",
   "name": "bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
